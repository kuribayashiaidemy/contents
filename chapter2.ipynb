{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()で可視化されない人はこのセルを実行してください。\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初めの一回だけこのセルを実行してください、データセットをダウンロードして展開します\n",
    "# 一回実行すれば、データセットはダウンロードされたままなので、再起動後等再び実行する必要はありません\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# URLを指定\n",
    "url = \"https://storage.googleapis.com/tutor-contents-dataset/4050_cleansing_data.zip\"\n",
    "save_name = url.split('/')[-1]\n",
    "\n",
    "# ダウンロードする\n",
    "mem = urllib.request.urlopen(url).read()\n",
    "\n",
    "# ファイルへ保存\n",
    "with open(save_name, mode='wb') as f:\n",
    "    f.write(mem)\n",
    "\n",
    "# zipファイルをカレントディレクトリに展開する\n",
    "zfile = zipfile.ZipFile(save_name)\n",
    "zfile.extractall('.')\n",
    "# ディレクトリ名を変更\n",
    "os.rename('4050_cleansing_data','4050_data_cleansing_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "rJe-OAmWlWf",
    "type": "chapter_name"
   },
   "source": [
    "#  DataFrameを用いたデータクレンジング\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "table"
   },
   "source": [
    "- **[2.1 CSV](#2.1-CSV)**\n",
    "    - **[2.1.1 Pandasを用いたCSVの読み込み](#2.1.1-Pandasを用いたCSVの読み込み)**\n",
    "    - **[2.1.2 CSVライブラリを用いたCSVの作成](#2.1.2-CSVライブラリを用いたCSVの作成)**\n",
    "    - **[2.1.3 Pandasを用いたCSVの作成](#2.1.3-Pandasを用いたCSVの作成)**\n",
    "<br><br>\n",
    "- **[2.2 DataFrameの復習](#2.2-DataFrameの復習)**\n",
    "    - **[2.2.1 DataFrameの復習](#2.2.1-DataFrameの復習)**\n",
    "<br><br>\n",
    "- **[2.3 欠損値](#2.3-欠損値)**\n",
    "    - **[2.3.1 リストワイズ削除/ペアワイズ削除](#2.3.1-リストワイズ削除/ペアワイズ削除)**\n",
    "    - **[2.3.2 欠損値の補完](#2.3.2-欠損値の補完)**\n",
    "    - **[2.3.3 欠損値の補完（平均値代入法）](#2.3.3-欠損値の補完（平均値代入法）)**\n",
    "<br><br>\n",
    "- **[2.4 データ集約](#2.4-データ集約)**\n",
    "    - **[2.4.1 キーごとの統計量の算出](#2.4.1-キーごとの統計量の算出)**\n",
    "    - **[2.4.2 重複データ](#2.4.2-重複データ)**\n",
    "    - **[2.4.3 マッピング](#2.4.3-マッピング)**\n",
    "    - **[2.4.4 ビン分割](#2.4.4-ビン分割)**\n",
    "<br><br>\n",
    "- **[2.5 まとめ問題（提出不要）](#2.5-まとめ問題（提出不要）)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "sectionId": "r1--uAX-l-G",
    "type": "section_name"
   },
   "source": [
    "## 2.1 CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "SkCUK3LoLeG",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.1.1 Pandasを用いたCSVの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "このセクションでは`CSV`と呼ばれるデータ形式を扱います。`CSV`は値をカンマで区切って羅列したファイルで、データ分析等において非常に扱いやすいので、一般的によく使われます。<br>\n",
    "<br>\n",
    "Pandasでcsvファイルを読み込むには、<b style='color:#AA0000'>read_csv()</b>関数を用います。\n",
    "```Python\n",
    "read_csv(\"csvファイルが置いてあるファイルパス\", header=)\n",
    "```\n",
    "headerオプションを省略すると読み込んだファイルの1行目を列名とし、`header=None`を指定するとPandasが適当な列名を割り当てます。また、`header=1`のように行番号を指定すると、読み込んだファイルの2行目のデータを列名とし、それ以降の行から読み込みを開始します。なお、行番号は0から開始するのでデータの1行目の行番号は0になります。<br>\n",
    "<br>\n",
    "例えば、列名の情報を持たないワインのデータセットをディレクトリから読み込みます。そのままでは数値が何を表しているのか分からないので、値の内容を示す列名（カラム）を追加します。\n",
    "\n",
    "```Python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./4050_data_cleansing_data/wine.csv\", header=None)\n",
    "\n",
    "# それぞれの数値が何を表しているのかカラムを追加します\n",
    "df.columns = [\"\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\",\"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\",\"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "df\n",
    "```\n",
    "\n",
    "ファイルパスの`./`はカレントディレクトリを示しています。カレントディレクトリとは、現在Pythonを実行している作業ディレクトリのことです。<br>\n",
    "<br>\n",
    "※ 最終行の`df`について<br>\n",
    "Aidemyの学習環境では、生成したDataFrameの変数名を最終行に記述すると、自動でHTMLとして装飾し描画するように設定しているため、print文を使用しなくてもDataFrameの内容が表示できます。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_10.png\" width=600>\n",
    "\n",
    "<b><center>図2.1.1 読み込み後にカラムを追加したワインのデータセット</center></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- オンラインでアヤメのデータ(`./4050_data_cleansing_data/iris.csv`)をCSV形式で取得し、PandasのDataFrame形式で出力してください。\n",
    "- カラムを左の列から順に`\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"class\"`と指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- csvファイルの読み込みは`read_csv(\"ファイルのパス\", header=)` を用います。\n",
    "- Aidemyの学習環境では、DataFrameの変数名を指定するだけでDataFrameを出力できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./4050_data_cleansing_data/iris.csv\", header=None)\n",
    "df.columns = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"class\"] \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "index_code_contains(\"read_csv\\(\",\"read_csv()関数を使ってください\")\n",
    "index_output_contains(\"     sepal length  sepal width  petal length  petal width           class\\\n",
    "0             5.1          3.5           1.4          0.2     Iris-setosa\\\n",
    "1             4.9          3.0           1.4          0.2     Iris-setosa\\\n",
    "2             4.7          3.2           1.3          0.2     Iris-setosa\\\n",
    "3             4.6          3.1           1.5          0.2     Iris-setosa\\\n",
    "4             5.0          3.6           1.4          0.2     Iris-setosa\\\n",
    "5             5.4          3.9           1.7          0.4     Iris-setosa\\\n",
    "6             4.6          3.4           1.4          0.3     Iris-setosa\\\n",
    "7             5.0          3.4           1.5          0.2     Iris-setosa\\\n",
    "8             4.4          2.9           1.4          0.2     Iris-setosa\\\n",
    "9             4.9          3.1           1.5          0.1     Iris-setosa\\\n",
    "10            5.4          3.7           1.5          0.2     Iris-setosa\\\n",
    "11            4.8          3.4           1.6          0.2     Iris-setosa\\\n",
    "12            4.8          3.0           1.4          0.1     Iris-setosa\\\n",
    "13            4.3          3.0           1.1          0.1     Iris-setosa\\\n",
    "14            5.8          4.0           1.2          0.2     Iris-setosa\\\n",
    "15            5.7          4.4           1.5          0.4     Iris-setosa\\\n",
    "16            5.4          3.9           1.3          0.4     Iris-setosa\\\n",
    "17            5.1          3.5           1.4          0.3     Iris-setosa\\\n",
    "18            5.7          3.8           1.7          0.3     Iris-setosa\\\n",
    "19            5.1          3.8           1.5          0.3     Iris-setosa\\\n",
    "20            5.4          3.4           1.7          0.2     Iris-setosa\\\n",
    "21            5.1          3.7           1.5          0.4     Iris-setosa\\\n",
    "22            4.6          3.6           1.0          0.2     Iris-setosa\\\n",
    "23            5.1          3.3           1.7          0.5     Iris-setosa\\\n",
    "24            4.8          3.4           1.9          0.2     Iris-setosa\\\n",
    "25            5.0          3.0           1.6          0.2     Iris-setosa\\\n",
    "26            5.0          3.4           1.6          0.4     Iris-setosa\\\n",
    "27            5.2          3.5           1.5          0.2     Iris-setosa\\\n",
    "28            5.2          3.4           1.4          0.2     Iris-setosa\\\n",
    "29            4.7          3.2           1.6          0.2     Iris-setosa\\\n",
    "..            ...          ...           ...          ...             ...\\\n",
    "120           6.9          3.2           5.7          2.3  Iris-virginica\\\n",
    "121           5.6          2.8           4.9          2.0  Iris-virginica\\\n",
    "122           7.7          2.8           6.7          2.0  Iris-virginica\\\n",
    "123           6.3          2.7           4.9          1.8  Iris-virginica\\\n",
    "124           6.7          3.3           5.7          2.1  Iris-virginica\\\n",
    "125           7.2          3.2           6.0          1.8  Iris-virginica\\\n",
    "126           6.2          2.8           4.8          1.8  Iris-virginica\\\n",
    "127           6.1          3.0           4.9          1.8  Iris-virginica\\\n",
    "128           6.4          2.8           5.6          2.1  Iris-virginica\\\n",
    "129           7.2          3.0           5.8          1.6  Iris-virginica\\\n",
    "130           7.4          2.8           6.1          1.9  Iris-virginica\\\n",
    "131           7.9          3.8           6.4          2.0  Iris-virginica\\\n",
    "132           6.4          2.8           5.6          2.2  Iris-virginica\\\n",
    "133           6.3          2.8           5.1          1.5  Iris-virginica\\\n",
    "134           6.1          2.6           5.6          1.4  Iris-virginica\\\n",
    "135           7.7          3.0           6.1          2.3  Iris-virginica\\\n",
    "136           6.3          3.4           5.6          2.4  Iris-virginica\\\n",
    "137           6.4          3.1           5.5          1.8  Iris-virginica\\\n",
    "138           6.0          3.0           4.8          1.8  Iris-virginica\\\n",
    "139           6.9          3.1           5.4          2.1  Iris-virginica\\\n",
    "140           6.7          3.1           5.6          2.4  Iris-virginica\\\n",
    "141           6.9          3.1           5.1          2.3  Iris-virginica\\\n",
    "142           5.8          2.7           5.1          1.9  Iris-virginica\\\n",
    "143           6.8          3.2           5.9          2.3  Iris-virginica\\\n",
    "144           6.7          3.3           5.7          2.5  Iris-virginica\\\n",
    "145           6.7          3.0           5.2          2.3  Iris-virginica\\\n",
    "146           6.3          2.5           5.0          1.9  Iris-virginica\\\n",
    "147           6.5          3.0           5.2          2.0  Iris-virginica\\\n",
    "148           6.2          3.4           5.4          2.3  Iris-virginica\\\n",
    "149           5.9          3.0           5.1          1.8  Iris-virginica\",\"dfを出力してください。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "Hkyvt3IjUef",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.1.2 CSVライブラリを用いたCSVの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "Python3に標準で搭載されているCSVライブラリを用いてCSVデータファイルを作成します。<br>\n",
    "<br>\n",
    "過去10回分のオリンピック開催の都市、開催の年、季節のデータをCSVデータファイルとして出力します。\n",
    "```Python\n",
    "import csv\n",
    "\n",
    "# with文を用います\n",
    "# csv0.csvファイルを変数csvfileとして、書き込みモード （\"w\"）で開きます\n",
    "with open(\"./4050_data_cleansing_data/csv0.csv\", \"w\") as csvfile:\n",
    "    # writerメソッドには引数として、変数csvfileと改行コード（\\n）を指定します\n",
    "    writer = csv.writer(csvfile, lineterminator=\"\\n\")\n",
    "    # writerow（リスト）を用いて行を追加します\n",
    "    writer.writerow([\"city\", \"year\", \"season\"])\n",
    "    writer.writerow([\"Nagano\", 1998, \"winter\"])\n",
    "    writer.writerow([\"Sydney\", 2000, \"summer\"])\n",
    "    writer.writerow([\"Salt Lake City\", 2002, \"winter\"])\n",
    "    writer.writerow([\"Athens\", 2004, \"summer\"])\n",
    "    writer.writerow([\"Torino\", 2006, \"winter\"])\n",
    "    writer.writerow([\"Beijing\", 2008, \"summer\"])\n",
    "    writer.writerow([\"Vancouver\", 2010, \"winter\"])\n",
    "    writer.writerow([\"London\", 2012, \"summer\"])\n",
    "    writer.writerow([\"Sochi\", 2014, \"winter\"])\n",
    "    writer.writerow([\"Rio de Janeiro\", 2016, \"summer\"])\n",
    "    \n",
    "# 出力\n",
    "# csv0.csvファイルを変数csvfileとして、読み込みモード(\"r\")で開きます\n",
    "with open(\"./4050_data_cleansing_data/csv0.csv\", \"r\") as csvfile:\n",
    "    print(csvfile.read())\n",
    "```\n",
    "実行するとcsv0.csvというCSVデータファイルが作成され、データの内容が表示されます。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_20.png\">\n",
    "\n",
    "なお、CSVデータファイルを作成した場所を調べるには、`import os`を行い、`print(os.getcwd())`を実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- csvモジュールを使って、フォルダ`4050_data_cleansing_data`の中にcsvファイル`csv０.csv`を作成してください。\n",
    "\n",
    "ファイルに書き込む内容は任意に決めて構いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- 行を追加するには`writerow(リスト型)`が使えます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./4050_data_cleansing_data/csv0.csv\", \"w\") as csvfile:\n",
    "    writer = csv.writer(csvfile, lineterminator=\"\\n\")\n",
    "    writer.writerow([\"city\", \"year\", \"season\"])\n",
    "    writer.writerow([\"Nagano\", 1998, \"winter\"])\n",
    "    writer.writerow([\"Sydney\", 2000, \"summer\"])\n",
    "    writer.writerow([\"Salt Lake City\", 2002, \"winter\"])\n",
    "    writer.writerow([\"Athens\", 2004, \"summer\"])\n",
    "    writer.writerow([\"Torino\", 2006, \"winter\"])\n",
    "    writer.writerow([\"Beijing\", 2008, \"summer\"])\n",
    "    writer.writerow([\"Vancouver\", 2010, \"winter\"])\n",
    "    writer.writerow([\"London\", 2012, \"summer\"])\n",
    "    writer.writerow([\"Sochi\", 2014, \"winter\"])\n",
    "    writer.writerow([\"Rio de Janeiro\", 2016, \"summer\"])\n",
    "\n",
    "with open(\"./4050_data_cleansing_data/csv0.csv\", \"r\") as csvfile:\n",
    "    print(csvfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "index_code_contains(\"writerow\", failure_msg=\"行を追加するにはwriterowを用います。\")\n",
    "index_code_contains(\"csv\", failure_msg=\"問題文にしたがってください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "S1gDthLjIeG",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.1.3 Pandasを用いたCSVの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "CSVライブラリを用いずに <b>Pandasを用いてもCSVデータを作成</b> することができます。PandasDataFrame形式のデータをCSVデータにする時はPandasを用いた方が便利です。<br>\n",
    "<br>\n",
    "Pandasでcsvファイルを作成するには、<b style='color: #AA0000'>to_csv()</b>関数を用います。\n",
    "\n",
    "```Python\n",
    "to_csv(\"作成するcsvファイル名\")\n",
    "```\n",
    "\n",
    "<br>\n",
    "DataFrameの例として先のサンプルと同様、過去10回分のオリンピック開催の都市、開催の年、季節のデータをCSVデータファイルとして出力します。\n",
    "\n",
    "```Python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\"city\": [\"Nagano\", \"Sydney\", \"Salt Lake City\", \"Athens\", \"Torino\", \"Beijing\", \"Vancouver\", \"London\", \"Sochi\", \"Rio de Janeiro\"], \n",
    "        \"year\": [1998, 2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016],\n",
    "        \"season\": [\"winter\", \"summer\", \"winter\", \"summer\", \"winter\", \"summer\", \"winter\", \"summer\", \"winter\", \"summer\"]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"4050_data_cleansing_data/csv1.csv\")\n",
    "```  \n",
    "これを実行すると`csv1.csv`というファイルが`cleansing_dataディレクトリ`に作成されます。\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_30.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- PandasのDataFrame`data`を`OSlist.csv`というファイル名のCSVデータ形式で出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\"OS\": [\"Machintosh\", \"Windows\", \"Linux\"],\n",
    "        \"release\": [1984, 1985, 1991],\n",
    "        \"country\": [\"US\", \"US\", \"\"]}\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- CSVデータファイルを作成するには、to_csv(\"ファイル名\")関数を用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\"OS\": [\"Machintosh\", \"Windows\", \"Linux\"],\n",
    "        \"release\": [1984, 1985, 1991],\n",
    "        \"country\": [\"US\", \"US\", \"\"]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"OSlist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "index_code_contains(\"OSlist.csv\", failure_msg=\"問題文にしたがってください。\")\n",
    "index_code_contains(\"to_csv\", failure_msg=\"to_csv(ファイル名)を用います。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "sectionId": "SyGb_C7Zxbz",
    "type": "section_name"
   },
   "source": [
    "## 2.2 DataFrameの復習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "r1bPF3LiIgG",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.2.1 DataFrameの復習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "DataFrameについては <a href='/courses/4010' target='_blank'>ライブラリ「Pandas」基礎（表計算）</a> の「2.2 DataFrameの連結」で詳しく解説しています。<br>\n",
    "ここでは簡単な問題を解いて基本を確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- `attri_data_frame1`へ`attri_data_frame2`の行を追加し出力してください。ただし、行を追加した後のDataFrameは`ID`で昇順になるようにし、行番号も昇順になるようにしてください。\n",
    "- 出力には`print`を使用せず、DataFrame名をそのまま記述してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\": [\"100\", \"101\", \"102\", \"103\", \"104\", \"106\", \"108\", \"110\", \"111\", \"113\"],\n",
    "               \"city\": [\"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\", \"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\"],\n",
    "               \"birth_year\": [1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981],\n",
    "               \"name\": [\"Hiroshi\", \"Akiko\", \"Yuki\", \"Satoru\", \"Steeve\", \"Mituru\", \"Aoi\", \"Tarou\", \"Suguru\", \"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "\n",
    "attri_data2 = {\"ID\": [\"107\", \"109\"],\n",
    "               \"city\": [\"Sendai\", \"Nagoya\"],\n",
    "               \"birth_year\": [1994, 1988]}\n",
    "attri_data_frame2 = DataFrame(attri_data2)\n",
    "\n",
    "# ここに解答を記述してください\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "type": "hint"
   },
   "source": [
    "- 行の追加には `append(行を追加したいDataFrameの変数名)`を用います。\n",
    "- データの並び替えには`sort_values(by=\"列の名前\")`を用います。\n",
    "- 行番号を振り直すには`reset_index(drop=True)`を用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\": [\"100\", \"101\", \"102\", \"103\", \"104\", \"106\", \"108\", \"110\", \"111\", \"113\"],\n",
    "               \"city\": [\"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\", \"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\"],\n",
    "               \"birth_year\": [1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981],\n",
    "               \"name\": [\"Hiroshi\", \"Akiko\", \"Yuki\", \"Satoru\", \"Steeve\", \"Mituru\", \"Aoi\", \"Tarou\", \"Suguru\", \"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "\n",
    "attri_data2 = {\"ID\": [\"107\", \"109\"],\n",
    "               \"city\": [\"Sendai\", \"Nagoya\"],\n",
    "               \"birth_year\": [1994, 1988]}\n",
    "attri_data_frame2 = DataFrame(attri_data2)\n",
    "\n",
    "# ここに解答を記述してください\n",
    "show_data = attri_data_frame1.append(attri_data_frame2).sort_values(\n",
    "    by=\"ID\", ascending=True).reset_index(drop=True)\n",
    "show_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "check_output_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "sectionId": "HJ7-uRXZlWz",
    "type": "section_name"
   },
   "source": [
    "## 2.3 欠損値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "BkfPFn8s8xG",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.3.1 リストワイズ削除/ペアワイズ削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "このセクションでは欠損値の扱いについて学びます。<br>\n",
    "<br>\n",
    "読み込んだデータに空白などがあると欠損値`NaN`（Not a Number）であると認識されます。データの精度を高めるために、欠損値`NaN`を削除するには<b style='color:#AA0000'>dropna()</b>関数を用います。<br>\n",
    "<br>\n",
    "まずは、わざと表の一部を欠損させた表をランダムに作成します。<br>\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "# 一部のデータをわざと欠損させます\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[2, 2] = NA\n",
    "sample_data_frame.iloc[5:, 3] = NA\n",
    "\n",
    "sample_data_frame\n",
    "```\n",
    "\n",
    "次のようなDataFrameが生成されます。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_40.png\" >\n",
    "\n",
    "データ欠損のある行や列（NaNを含む行）をまるごと消去することを`リストワイズ削除`といいます。`dropna()`関数を用いて、1つでもNaNを含む行をすべて取り除きます。また、引数に`axis=1`を指定すると1つでもNaNを含む列を取り除きます。\n",
    "\n",
    "```Python\n",
    "sample_data_frame.dropna()\n",
    "```\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_50.png\" >\n",
    "\n",
    "リストワイズ法で欠損のある行をすべて削除してしまうとデータが少なすぎる場合、利用可能なデータのみを用いる方法もあります。欠損の少ない列（例えば、0列目と1列目）を残し、そこからNaNを含む行を消去することを`ペアワイズ削除`といいます。\n",
    "\n",
    "```Python\n",
    "sample_data_frame[[0, 1]].dropna()\n",
    "```\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_60.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- DataFrame `sample_data_frame` の0列と2列を残し、NaNを含む行をすべて削除して出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[2, 2] = NA\n",
    "sample_data_frame.iloc[5:, 3] = NA\n",
    "\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- ペアワイズ削除の考え方を用います。最初に0列と2列を残して削除し、その後でNaNを含む行を削除します。\n",
    "```\n",
    "sample_data_frame[[0, 2]].dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[2, 2] = NA\n",
    "sample_data_frame.iloc[5:, 3] = NA\n",
    "\n",
    "# ここに解答を記述してください\n",
    "sample_data_frame[[0, 2]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "check_output_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "ryXwYhLsIgG",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.3.2 欠損値の補完"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "データの精度を高めるには欠損値を削除する以外に、代替データを欠損値に代入する方法もあります。<br>\n",
    "欠損値NaNに代替データを代入（置き換え）するには<b style='color:#AA0000'>fillna()</b>関数を用います。<br>\n",
    "<br>\n",
    "わざと表の一部を欠損させた表をランダムに作成します。\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "# 一部のデータをわざと欠損させます\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[2, 2] = NA\n",
    "sample_data_frame.iloc[5:, 3] = NA\n",
    "```\n",
    "\n",
    "`fillna()`関数を用いると、引数として与えた数をNaNの部分に代入します。今回は0で埋めてみます。\n",
    "\n",
    "```Python\n",
    "sample_data_frame.fillna(0)\n",
    "```\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_70.png\" >\n",
    "\n",
    "`method`に`ffill`を指定すると前行の値で埋めることができます。\n",
    "\n",
    "```Python\n",
    "sample_data_frame.fillna(method=\"ffill\")\n",
    "```\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_80.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- DataFrame `sample_data_frame` のNaNを前行の値で埋めて出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[6:, 2] = NA\n",
    "\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- 前行の値で埋める場合は、`method`に`fillna`を指定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[6:, 2] = NA\n",
    "\n",
    "# ここに解答を記述してください\n",
    "sample_data_frame.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "check_output_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "rJVPtnIoLlz",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.3.3 欠損値の補完（平均値代入法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "欠損値をその列（または行）の平均値によって穴埋めをする方法を<b style='color: #AA0000'>平均値代入法</b>といいます。<br>\n",
    "平均値は`mean()`関数を用いて算出します。\n",
    "```Python\n",
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "# 一部のデータをわざと欠損させます\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[2, 2] = NA\n",
    "sample_data_frame.iloc[5:, 3] = NA\n",
    "\n",
    "# fillnaを用いてNaNの部分にその列の平均値を代入します\n",
    "sample_data_frame.fillna(sample_data_frame.mean())\n",
    "```\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_90.png\" >\n",
    "\n",
    "**<center>図2.3.3-1 平均値を代入したあとのデータの様子</center>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- DataFrame `sample_data_frame` のNaNを列の平均値で埋めて出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[6:, 2] = NA\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- 値を代入するには`fillna`を用います。\n",
    "- 平均値は`mean()`関数を用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "sample_data_frame = pd.DataFrame(np.random.rand(10, 4))\n",
    "\n",
    "sample_data_frame.iloc[1, 0] = NA\n",
    "sample_data_frame.iloc[6:, 2] = NA\n",
    "\n",
    "sample_data_frame.fillna(sample_data_frame.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "check_output_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "sectionId": "S1NbuCm-eWf",
    "type": "section_name"
   },
   "source": [
    "## 2.4 データ集約"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "SyBvF3UiUxz",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.4.1 キーごとの統計量の算出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "このセクションではデータの集約について学びます。<br>\n",
    "<br>\n",
    "統計量は代表値と散布度に区分できます。代表値とはデータの基本的な特徴を表す値のことで、例えば、平均値、最大値、最小値などのことです。<br>\n",
    "<a href='/courses/4050/exercises/SkCUK3LoLeG' target='_blank'>2.1.1 Pandasを用いたCSVの読み込み</a>で用いたワインのデータセットを読み込んでキーごとの平均値を算出してみます。\n",
    "```Python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./4050_data_cleansing_data/wine.csv\", header=None)\n",
    "df.columns=[\"\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\",\"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\",\"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "\n",
    "# DataFrame `df` のキー\"Alcohol\"の平均値を算出します\n",
    "df[\"Alcohol\"].mean()\n",
    "```\n",
    "```Python\n",
    "# 出力結果\n",
    "13.000617977528091\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- 解説で使用したワインのデータセットを読み込み、\"Magnesium\"の平均値を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./4050_data_cleansing_data/wine.csv\", header=None)\n",
    "df.columns = [\"\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \"Total phenols\", \"Flavanoids\",\n",
    "              \"Nonflavanoid phenols\", \"Proanthocyanins\", \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- \"Magnesium\"の列を抽出し、`mean()`メソッドを用いて平均値を求めます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./4050_data_cleansing_data/wine.csv\", header=None)\n",
    "df.columns = [\"\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \"Total phenols\", \"Flavanoids\",\n",
    "              \"Nonflavanoid phenols\", \"Proanthocyanins\", \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "\n",
    "df[\"Magnesium\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "index_output_contains(\"99\\.74\",\"出力が違います\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "r1IwYn8j8lz",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.4.2 重複データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "データの重複がある場合、そのデータを削除してデータの精度を高めます。<br>\n",
    "実際にデータの重複があるDataFrameを用意して、重複データの抽出や削除を行ってみます。\n",
    "```Python\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "dupli_data = DataFrame({\"col1\":[1, 1, 2, 3, 4, 4, 6, 6]\n",
    "                       ,\"col2\":[\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"b\", \"b\"]})\n",
    "dupli_data\n",
    "```\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_100.png\" >\n",
    "\n",
    "**<center>図2.4.2-1 生成された直後のデータ</center>**\n",
    "\n",
    "<b style='color: #AA0000'>duplicated()</b>メソッドを用いると、重複がある行に`True`を返すSeries型のデータを生成し、重複データを抽出します。\n",
    "```Python\n",
    "# 重複データを抽出します\n",
    "dupli_data.duplicated()\n",
    "```\n",
    "```Python\n",
    "# 出力結果\n",
    "0    False\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "4    False\n",
    "5     True\n",
    "6    False\n",
    "7     True\n",
    "dtype: bool\n",
    "```\n",
    "`dtype`とは \"Data Type\" のことで、要素のデータ型を示します。<br>\n",
    "<br>\n",
    "`drop_duplicates()`メソッドを用いると、重複するデータを削除します。\n",
    "```Python\n",
    "dupli_data.drop_duplicates()\n",
    "```\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_110.png\" >\n",
    "\n",
    "**<center>図2.4.2-2 重複を除いたあとのデータ</center>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- DataFrame `dupli_data` には重複したデータがあります。重複データを削除して新たなDataFrameを出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "dupli_data = DataFrame({\"col1\":[1, 1, 2, 3, 4, 4, 6, 6, 7, 7, 7, 8, 9, 9]\n",
    "                       ,\"col2\":[\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"b\", \"b\", \"d\", \"d\", \"c\", \"b\", \"c\", \"c\"]})\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- 重複データの削除には`drop_duplicates()`メソッドを用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "dupli_data = DataFrame({\"col1\":[1, 1, 2, 3, 4, 4, 6, 6, 7, 7, 7, 8, 9, 9]\n",
    "                       ,\"col2\":[\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"b\", \"b\", \"d\", \"d\", \"c\", \"b\", \"c\", \"c\"]})\n",
    "\n",
    "dupli_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "index_code_contains(\"drop_duplicates()\", failure_msg=\"重複データの削除はdrop_duplicates()を用います\")\n",
    "check_output_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "HkvPKnLi8gM",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.4.3 マッピング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "マッピングとは共通のキーを持つデータに対して、別のテーブルからキーに対応する値を参照する処理です。<br>\n",
    "実際にDataFrameを用意して、マッピング処理を行ってみます。\n",
    "```Python\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\": [\"100\", \"101\", \"102\", \"103\", \"104\", \"106\", \"108\", \"110\", \"111\", \"113\"]\n",
    "        ,\"city\": [\"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\", \"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\"]\n",
    "        ,\"birth_year\" :[1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981]\n",
    "        ,\"name\" :[\"Hiroshi\", \"Akiko\", \"Yuki\", \"Satoru\", \"Steeve\", \"Mituru\", \"Aoi\", \"Tarou\", \"Suguru\", \"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "\n",
    "attri_data_frame1\n",
    "```\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_120.png\" >\n",
    "\n",
    "**<center>図2.4.3-1 生成された直後のデータ</center>**\n",
    "\n",
    "cityに対応する地域名を持つ、辞書型のデータを作成します。\n",
    "```Python\n",
    "city_map ={\"Tokyo\":\"Kanto\"\n",
    "          ,\"Hokkaido\":\"Hokkaido\"\n",
    "          ,\"Osaka\":\"Kansai\"\n",
    "          ,\"Kyoto\":\"Kansai\"}\n",
    "city_map\n",
    "```\n",
    "はじめに用意した`attri_data_frame1`のcityカラムをキーに、`city_map`から対応する地域名データを参照して、新しいカラムに追加します。これがマッピング処理です。Excelに詳しい方であればvlookup関数のような処理をイメージしてください。<br>\n",
    "`map()`関数を用いてマッピング処理を行い、新しいカラムとして`region`を`attri_data_frame1`に追加します。\n",
    "```Python\n",
    "attri_data_frame1[\"region\"] = attri_data_frame1[\"city\"].map(city_map)\n",
    "attri_data_frame1\n",
    "```\n",
    "出力結果を見ると、regionカラムに地域名が追加されているのが分かります。<br>\n",
    "対応するデータが`city_map`に存在しない要素には`NaN`が埋められます。\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/4050_data_cleansing/cleansing_chap2_130.png\" >\n",
    "\n",
    "**<center>図2.4.3-2 regionカラムが追加されたデータ</center>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- `Tokyo`、`Hokkaido`の要素が`east` 、`Osaka`、`Kyoto`の要素が`west`である辞書を新たに作成してください。<br>\n",
    "辞書名は任意です。\n",
    "- DataFrame`attri_data1`の`city`をキーに上で作成した辞書を参照して新しい列`WE`を追加し、その結果を出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\": [\"100\", \"101\", \"102\", \"103\", \"104\", \"106\", \"108\", \"110\", \"111\", \"113\"]\n",
    "        ,\"city\": [\"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\", \"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\"]\n",
    "        ,\"birth_year\" :[1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981]\n",
    "        ,\"name\" :[\"Hiroshi\", \"Akiko\", \"Yuki\", \"Satoru\", \"Steeve\", \"Mituru\", \"Aoi\", \"Tarou\", \"Suguru\", \"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- データを参照するには`map()`関数を用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\": [\"100\", \"101\", \"102\", \"103\", \"104\", \"106\", \"108\", \"110\", \"111\", \"113\"]\n",
    "        ,\"city\": [\"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\", \"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\"]\n",
    "        ,\"birth_year\" :[1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981]\n",
    "        ,\"name\" :[\"Hiroshi\", \"Akiko\", \"Yuki\", \"Satoru\", \"Steeve\", \"Mituru\", \"Aoi\", \"Tarou\", \"Suguru\", \"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "\n",
    "WE_map = {\"Tokyo\":\"east\"\n",
    "          ,\"Hokkaido\":\"east\"\n",
    "          ,\"Osaka\":\"west\"\n",
    "          ,\"Kyoto\":\"west\"}\n",
    "\n",
    "attri_data_frame1[\"WE\"] = attri_data_frame1[\"city\"].map(WE_map)\n",
    "\n",
    "attri_data_frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "check_output_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 4050,
    "exerciseId": "rJdDt3LjIgM",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5,
    "type": "code_session_name"
   },
   "source": [
    "### 2.4.4 ビン分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "ビン分割とは、数値データを大まかに区切ってカテゴリ分けをする処理のことです。例えば、年齢を0～9歳、10～19歳、20～29歳のように分ける処理です。あらかじめビン分割したリストを用意してpandasの`cut()`関数を用いて処理を行います。<br>\n",
    "例えば、<a href='/courses/4050/exercises/HkvPKnLi8gM' target='_blank'>2.4.3 マッピング</a>で用いたデータセットを使用してビン分割を行ってみます。\n",
    "```Python\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\": [100,101,102,103,104,106,108,110,111,113]\n",
    "        ,\"city\": [\"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\", \"Tokyo\", \"Osaka\", \"Kyoto\", \"Hokkaido\", \"Tokyo\"]\n",
    "        ,\"birth_year\" :[1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981]\n",
    "        ,\"name\" :[\"Hiroshi\", \"Akiko\", \"Yuki\", \"Satoru\", \"Steeve\", \"Mituru\", \"Aoi\", \"Tarou\", \"Suguru\", \"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "```\n",
    "分割の粒度をリストで指定し、ビン分割を実施します。ここでは`birth_year`に着目します。\n",
    "```Python\n",
    "# 分割の粒度のリストを作成します\n",
    "birth_year_bins = [1980,1985,1990,1995,2000]\n",
    "\n",
    "#ビン分割を行いします\n",
    "birth_year_cut_data = pd.cut(attri_data_frame1.birth_year,birth_year_bins)\n",
    "birth_year_cut_data\n",
    "```\n",
    "```Python\n",
    "# 出力結果\n",
    "0    (1985, 1990]\n",
    "1    (1985, 1990]\n",
    "2    (1990, 1995]\n",
    "3    (1995, 2000]\n",
    "4    (1980, 1985]\n",
    "5    (1990, 1995]\n",
    "6    (1985, 1990]\n",
    "7    (1985, 1990]\n",
    "8    (1990, 1995]\n",
    "9    (1980, 1985]\n",
    "Name: birth_year, dtype: category\n",
    "Categories (4, interval[int64]): [(1980, 1985] < (1985, 1990] < (1990, 1995] < (1995, 2000]]\n",
    "```\n",
    "\"()\"はその値を含まず、\"[]\"はその値を含むことを意味します。例えば `(1985, 1990]` の場合、1985年は含まず，1990年は含まれます。<br>\n",
    "<br>\n",
    "それぞれのビンの数を集計したい場合は、`value_counts()`メソッドを用います。\n",
    "```Python\n",
    "pd.value_counts(birth_year_cut_data)\n",
    "```\n",
    "```Python\n",
    "# 出力結果\n",
    "(1985, 1990]    4\n",
    "(1990, 1995]    3\n",
    "(1980, 1985]    2\n",
    "(1995, 2000]    1\n",
    "Name: birth_year, dtype: int64\n",
    "```\n",
    "それぞれのビンに名前をつけることも可能です。\n",
    "```Python\n",
    "group_names = [\"first1980\", \"second1980\", \"first1990\", \"second1990\"]\n",
    "birth_year_cut_data = pd.cut(attri_data_frame1.birth_year,birth_year_bins,labels = group_names)\n",
    "pd.value_counts(birth_year_cut_data)\n",
    "```\n",
    "```Python\n",
    "# 出力結果\n",
    "second1980    4\n",
    "first1990     3\n",
    "first1980     2\n",
    "second1990    1\n",
    "Name: birth_year, dtype: int64\n",
    "```\n",
    "あらかじめ分割数を指定して分割することも可能です。これを用いると、ほぼ同じサイズのビンを作成することができます。`cut()`関数の第2引数に分割数を指定します。\n",
    "```Python\n",
    "pd.cut(attri_data_frame1.birth_year,2)\n",
    "```\n",
    "```Python\n",
    "# 出力結果\n",
    "0      (1989.0, 1997.0]\n",
    "1    (1980.984, 1989.0]\n",
    "2      (1989.0, 1997.0]\n",
    "3      (1989.0, 1997.0]\n",
    "4    (1980.984, 1989.0]\n",
    "5      (1989.0, 1997.0]\n",
    "6    (1980.984, 1989.0]\n",
    "7      (1989.0, 1997.0]\n",
    "8      (1989.0, 1997.0]\n",
    "9    (1980.984, 1989.0]\n",
    "Name: birth_year, dtype: category\n",
    "Categories (2, interval[float64]): [(1980.984, 1989.0] < (1989.0, 1997.0]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "- DataFrame`attri_data1`をIDで2つにビン分割して出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\":[100,101,102,103,104,106,108,110,111,113]\n",
    "        ,\"city\":[\"Tokyo\",\"Osaka\",\"Kyoto\",\"Hokkaido\",\"Tokyo\",\"Tokyo\",\"Osaka\",\"Kyoto\",\"Hokkaido\",\"Tokyo\"]\n",
    "        ,\"birth_year\":[1990,1989,1992,1997,1982,1991,1988,1990,1995,1981]\n",
    "        ,\"name\":[\"Hiroshi\",\"Akiko\",\"Yuki\",\"Satoru\",\"Steeve\",\"Mituru\",\"Aoi\",\"Tarou\",\"Suguru\",\"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "# ここに解答を記述してください\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- 分割数を指定して分割する場合、`cut()`関数の第2引数に分割数を渡します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "type": "answer"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (99.987, 106.5]\n",
       "1    (99.987, 106.5]\n",
       "2    (99.987, 106.5]\n",
       "3    (99.987, 106.5]\n",
       "4    (99.987, 106.5]\n",
       "5    (99.987, 106.5]\n",
       "6     (106.5, 113.0]\n",
       "7     (106.5, 113.0]\n",
       "8     (106.5, 113.0]\n",
       "9     (106.5, 113.0]\n",
       "Name: ID, dtype: category\n",
       "Categories (2, interval[float64]): [(99.987, 106.5] < (106.5, 113.0]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "attri_data1 = {\"ID\":[100,101,102,103,104,106,108,110,111,113]\n",
    "        ,\"city\":[\"Tokyo\",\"Osaka\",\"Kyoto\",\"Hokkaido\",\"Tokyo\",\"Tokyo\",\"Osaka\",\"Kyoto\",\"Hokkaido\",\"Tokyo\"]\n",
    "        ,\"birth_year\":[1990,1989,1992,1997,1982,1991,1988,1990,1995,1981]\n",
    "        ,\"name\":[\"Hiroshi\",\"Akiko\",\"Yuki\",\"Satoru\",\"Steeve\",\"Mituru\",\"Aoi\",\"Tarou\",\"Suguru\",\"Mitsuo\"]}\n",
    "attri_data_frame1 = DataFrame(attri_data1)\n",
    "\n",
    "pd.cut(attri_data_frame1.ID, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "sct"
   },
   "outputs": [],
   "source": [
    "execute_index()\n",
    "check_output_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "chapter_exam"
   },
   "source": [
    "## 2.5 まとめ問題（提出不要）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "description"
   },
   "source": [
    "今までの復習をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "question"
   },
   "source": [
    "以下のコメントアウトの下にコードを書いてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "index"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./4050_data_cleansing_data/wine.csv\", header=None)\n",
    "#カラムにそれぞれの数値が何を表しているかを追加します\n",
    "df.columns=[\"\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\",\n",
    "            \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\",\n",
    "            \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "\n",
    "#変数dfの上から１０行を変数df_tenに代入し、表示する操作です\n",
    "df_ten = df.head(10)\n",
    "print(df_ten)\n",
    "\n",
    "#データの一部を欠損させてください\n",
    "df_ten.iloc[1,0] = \n",
    "df_ten.iloc[2,3] = \n",
    "df_ten.iloc[4,8] = \n",
    "df_ten.iloc[7,3] = \n",
    "print(df_ten)\n",
    "\n",
    "#fillnaを用いてNaNの部分にその列の平均値を代入しください\n",
    "df_ten = \n",
    "print(df_ten)\n",
    "\n",
    "#重複している行を削除してください\n",
    "df_ten = df_ten.append(df_ten.loc[3])\n",
    "df_ten = df_ten.append(df_ten.loc[6])\n",
    "df_ten = df_ten.append(df_ten.loc[9])\n",
    "df_ten = \n",
    "print(df_ten)\n",
    "\n",
    "#Alcohol列の分割の粒度リストを作成してください\n",
    "alcohol_bins = [0,5,10,15,20,25]\n",
    "alcoholr_cut_data = \n",
    "\n",
    "#ビン数を集計し出力ください\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "hint"
   },
   "source": [
    "- このチャプターで学んだことを確認しましょう。2.3では欠損値の補完を、2.4では重複の削除・ビン分割などを学びました。\n",
    "- 登場する `.head()` という関数は、DataFrameの上から指定した数の行を取り出してくれるものです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "type": "answer"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from numpy import nan as NA\n",
    "\n",
    "df = pd.read_csv(\"./4050_data_cleansing_data/wine.csv\", header=None)\n",
    "#カラムにそれぞれの数値が何を表しているかを追加します\n",
    "df.columns=[\"\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\",\n",
    "            \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\",\n",
    "            \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "\n",
    "#変数dfの上から１０行を変数df_tenに代入し、表示する操作です\n",
    "df_ten = df.head(10)\n",
    "print(df_ten)\n",
    "\n",
    "#データの一部を欠損させてください\n",
    "df_ten.iloc[1,0] = NA\n",
    "df_ten.iloc[2,3] = NA\n",
    "df_ten.iloc[4,8] = NA\n",
    "df_ten.iloc[7,3] = NA\n",
    "print(df_ten)\n",
    "\n",
    "#fillnaを用いてNaNの部分にその列の平均値を代入しください\n",
    "df_ten = df_ten.fillna(df_ten.mean())\n",
    "print(df_ten)\n",
    "\n",
    "#\"Alcohol\"列の平均を出力してください\n",
    "print(df_ten[\"Alcohol\"].mean())\n",
    "\n",
    "#重複している行を削除してください\n",
    "df_ten = df_ten.append(df_ten.loc[3])\n",
    "df_ten = df_ten.append(df_ten.loc[6])\n",
    "df_ten = df_ten.append(df_ten.loc[9])\n",
    "df_ten = df_ten.drop_duplicates()\n",
    "print(df_ten)\n",
    "\n",
    "#Alcohol列の分割の粒度リストを作成してください\n",
    "alcohol_bins = [0,5,10,15,20,25]\n",
    "alcoholr_cut_data = pd.cut(df_ten[\"Alcohol\"],alcohol_bins)\n",
    "\n",
    "#ビン数の集計\n",
    "print(pd.value_counts(alcoholr_cut_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "commentary"
   },
   "source": [
    "DataFrameに関する基本的な事項は、不安な点があればPandasの教材も参考にしてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
